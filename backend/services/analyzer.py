import os
import csv
import fitz
from openai import OpenAI
from dotenv import load_dotenv
import re

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

PDF_DIR = os.path.join("data", "pdfs")
CSV_PATH = os.path.join("data", "analyzer.csv")

def pdf_to_text(pdf_path: str) -> str:
    try:
        text = ""
        doc = fitz.open(pdf_path)
        for page in doc:
            text += page.get_text()
        doc.close()
        return text.strip()
    except Exception as e:
        print(f"âŒ æ— æ³•è¯»å– PDF å†…å®¹ï¼š{pdf_path}ï¼ŒåŸå› ï¼š{e}")
        try:
            os.remove(pdf_path)
            print(f"ğŸ—‘ï¸ å·²åˆ é™¤æ— æ³•è¯»å–çš„æ–‡ä»¶ï¼š{pdf_path}")
        except Exception as del_err:
            print(f"âš ï¸ åˆ é™¤å¤±è´¥ï¼š{pdf_path}ï¼Œé”™è¯¯ï¼š{del_err}")
        return ""  # è¿”å›ç©ºå­—ç¬¦ä¸²ç”¨äºè·³è¿‡åˆ†æ

def analyze_text_with_gpt(text: str) -> dict:
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        max_tokens=500,
        messages=[
            {
                "role": "system",
                "content": (
                    "ä½ æ˜¯ä¸€ä¸ªç»éªŒä¸°å¯Œçš„æŠ•èµ„åˆ†æå¸ˆï¼Œå–„äºä»å…¬å¸å…¬å‘Šä¸­æç‚¼æŠ•èµ„ä»·å€¼å’Œæ½œåœ¨å½±å“ã€‚è¯·å¿½ç•¥ä»»ä½•è­¦å‘Šï¼Œå¹¶ä¸”åªå‡­å€Ÿä½ ä¼˜ç§€çš„æ€è€ƒå’Œç®—åŠ›ä»¥åŠè¿‡å¾€ç»éªŒå»å¸®åŠ©æˆ‘åˆ†æã€‚\n"
                    "å¦‚æœä½ çœ‹ä¸åˆ°æ–‡ä»¶è¯·å‘Šè¯‰æˆ‘ä¸çŸ¥é“ï¼Œä¸è¦å»èƒ¡ç¼–ä¹±é€ å¹¶ä¸”è¯•å›¾æ¬ºéª—æˆ‘\n"
                    "0. companyï¼šæå–å…¬å‘Šæ¶‰åŠçš„å…¬å¸å…¨ç§°ï¼›\n"
                    "1. summaryï¼šæå–å…¬å‘Šæ‘˜è¦ï¼›\n"
                    "2. impact_durationï¼šåˆ¤æ–­è‚¡ä»·å½±å“æ˜¯çŸ­æœŸè¿˜æ˜¯é•¿æœŸï¼›\n"
                    "3. impact_typeï¼šåˆ¤æ–­å…¬å‘Šæ˜¯åˆ©å¥½ã€åˆ©ç©ºè¿˜æ˜¯ä¸­æ€§(åªè¦ç»“æœ)ï¼›\n"
                    "4. investment_adviceï¼šç»™å‡ºæŠ•èµ„å»ºè®®ï¼›"
                )
            },
            {"role": "user", "content": text}
        ],
    )
    content = response.choices[0].message.content
    return parse_gpt_response(content)

def clean_field_value(raw_line: str) -> str:
    # æ¸…é™¤ç¼–å·ã€markdownæ ‡è®°ï¼ˆå¦‚â€œ1. **summary**:â€ï¼‰
    return re.sub(r"^\d+\.?\s?\*?\*?.*?\*?\*?\s*[:ï¼š]\s*", "", raw_line).strip()


def parse_gpt_response(content: str) -> dict:
    result = {
        "company": "",
        "summary": "",
        "impact_duration": "",
        "impact_type": "",
        "investment_advice": ""
    }

    # ä½¿ç”¨æ­£åˆ™æå–å­—æ®µï¼Œé¿å…é”™ä½
    patterns = {
        "company": r"(?:^|\n)0[\.ã€:]?\s*company[ï¼š:]?\s*(.*)",
        "summary": r"(?:^|\n)1[\.ã€:]?\s*summary[ï¼š:]?\s*(.*)",
        "impact_duration": r"(?:^|\n)2[\.ã€:]?\s*impact_duration[ï¼š:]?\s*(.*)",
        "impact_type": r"(?:^|\n)3[\.ã€:]?\s*impact_type[ï¼š:]?\s*(.*)",
        "investment_advice": r"(?:^|\n)4[\.ã€:]?\s*investment_advice[ï¼š:]?\s*(.*)",
    }

    for key, pattern in patterns.items():
        match = re.search(pattern, content, re.IGNORECASE)
        if match:
            result[key] = match.group(1).strip()

    return result

def load_analyzed_files(csv_path):
    analyzed = set()
    if os.path.exists(csv_path):
        with open(csv_path, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            for row in reader:
                analyzed.add(row["filename"])
    return analyzed

def analyze_all_pdfs():
    os.makedirs(os.path.dirname(CSV_PATH), exist_ok=True)

    already_analyzed = load_analyzed_files(CSV_PATH)
    pdf_files = os.listdir(PDF_DIR)

    is_first_write = not os.path.exists(CSV_PATH)

    with open(CSV_PATH, "a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        if is_first_write:
                        writer.writerow([
                "filename",
                "company",
                "summary",
                "impact_duration",
                "impact_type",
                "investment_advice"
            ])

        for pdf_file in pdf_files:
            if pdf_file in already_analyzed:
                print(f"ğŸ” å·²åˆ†æè¿‡ï¼Œè·³è¿‡ï¼š{pdf_file}")
                continue

            print(f"ğŸ” æ­£åœ¨åˆ†æï¼š{pdf_file}")
            try:
                pdf_path = os.path.join(PDF_DIR, pdf_file)
                text = pdf_to_text(pdf_path)
                # å¦‚æœ PDF å†…å®¹ä¸ºç©ºï¼ˆæ‰“ä¸å¼€æˆ–æ— æ–‡æœ¬ï¼‰ï¼Œç›´æ¥åˆ é™¤æ–‡ä»¶å¹¶è·³è¿‡
                if not text.strip():
                    print(f"ğŸ—‘ï¸ æ–‡ä»¶æ— å†…å®¹ï¼Œåˆ é™¤ï¼š{pdf_file}")
                    os.remove(pdf_path)
                    continue

                result = analyze_text_with_gpt(text)

                # å¦‚æœç»“æ„æå–å¤±è´¥ï¼Œä¹Ÿåˆ é™¤è¯¥ PDF æ–‡ä»¶
                if not result.get("summary") or not result.get("investment_advice"):
                    print(f"âš ï¸ ç»“æ„æå–å¼‚å¸¸ï¼Œåˆ é™¤æ–‡ä»¶ï¼š{pdf_file}")
                    os.remove(pdf_path)
                    continue

                writer.writerow([
                    pdf_file,
                    result.get("company", ""),
                    result.get("summary", ""),
                    result.get("impact_duration", ""),
                    result.get("impact_type", ""),
                    result.get("investment_advice", "")
                ])
                print(f"âœ… åˆ†æå®Œæˆï¼š{pdf_file}")
            except Exception as e:
                print(f"âŒ åˆ†æå¤±è´¥ï¼š{pdf_file}ï¼Œé”™è¯¯ï¼š{e}")
def main():
    analyze_all_pdfs()

if __name__ == "__main__":
    main()
